{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolutional_VAE_MNIST_denoising.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsTklf+mkbR9OeeWtqjAWJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aneesh-kaitou1412/vae-mnist/blob/master/Convolutional_VAE_MNIST_denoising.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki5TYOKsetXX",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional VAE for Denoising Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ugHFv4W5IYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E23G2XsGfeX0",
        "colab_type": "text"
      },
      "source": [
        "## Loading MNIST and making a Noisy Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbCY2wq4f4X1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(images):\n",
        "  images = np.expand_dims(images, -1)\n",
        "  images = images.astype('float32') / 255\n",
        "  return images\n",
        "\n",
        "def generate_noisy(images, \n",
        "                   loc=0.5, \n",
        "                   scale=0.5, \n",
        "                   min_value=0.0, \n",
        "                   max_value=1.0,\n",
        "                   percent_distortion=0.65):\n",
        "  noise = np.random.normal(loc=loc, scale=scale, size=images.shape)\n",
        "  return np.clip(images + percent_distortion * noise, \n",
        "                 min_value, \n",
        "                 max_value)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDsAtG-Efkrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)\n",
        "\n",
        "x_train_noisy = generate_noisy(x_train)\n",
        "\n",
        "x_test_noisy = generate_noisy(x_test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y_kvYYMt2Dd",
        "colab_type": "text"
      },
      "source": [
        "## Build the Variational Autoencoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSVPFi-Tt9tC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network Parameters\n",
        "input_shape = (x_train.shape[1], x_train.shape[2], x_train.shape[3],)\n",
        "batch_size = 128\n",
        "latent_dim = 2\n",
        "\n",
        "# Encoder Decoder number of Convolutional Layers and Filters, \n",
        "# Kernel Sizes, Stride Sizes\n",
        "filter_sizes = [64, 32, 16]\n",
        "kernel_sizes = [3, 3, 3]\n",
        "stride_sizes = [2, 2, 1]\n",
        "\n",
        "encoding_activation='selu'\n",
        "decoding_activation='relu'"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXZY20Nwxzm4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "6e835f12-a2e4-4d6c-ed16-b8ade5b84d81"
      },
      "source": [
        "# Build the Encoder Model\n",
        "\n",
        "class SamplingLayer(layers.Layer):\n",
        "  \"\"\" Sampling Latent Space Vector using Reparametrization Trick \"\"\"\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    batch_size = tf.shape(z_mean)[0]\n",
        "    latent_dim = tf.shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape=(batch_size, latent_dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "inputs = layers.Input(shape=input_shape, name='encoder_input')\n",
        "x = inputs\n",
        "\n",
        "# Stack Convolutional Encoding Layers\n",
        "for filters, kernel_size, strides in \\\n",
        "    zip(filter_sizes, kernel_sizes, stride_sizes):\n",
        "  x = layers.Conv2D(filters=filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    strides=strides,\n",
        "                    activation=encoding_activation,\n",
        "                    padding='same')(x)\n",
        "\n",
        "# Final Shape before Dense Unit to build Decoder\n",
        "encoder_out_shape = K.int_shape(x)\n",
        "encoder_out_shape = (encoder_out_shape[1], \n",
        "                     encoder_out_shape[2], \n",
        "                     encoder_out_shape[3])\n",
        "\n",
        "# Generate Latent Space Paramters\n",
        "x = layers.Flatten()(x)\n",
        "z_mean = layers.Dense(units=latent_dim, name='z_mean')(x)\n",
        "z_log_var = layers.Dense(units=latent_dim, name='z_log_var')(x)\n",
        "z = SamplingLayer()([z_mean, z_log_var])\n",
        "\n",
        "# Make the Encoder Model\n",
        "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "encoder.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 14, 14, 64)   640         encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 7, 7, 32)     18464       conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 7, 7, 16)     4624        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 784)          0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 2)            1570        flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "z_log_var (Dense)               (None, 2)            1570        flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "sampling_layer_2 (SamplingLayer (None, 2)            0           z_mean[0][0]                     \n",
            "                                                                 z_log_var[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 26,868\n",
            "Trainable params: 26,868\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U99kMJqt27vy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "8f621670-190f-4d3d-84f0-08ddf7199634"
      },
      "source": [
        "# Build the Decoder Model\n",
        "\n",
        "z = layers.Input(shape=(latent_dim,), name='decoder_input')\n",
        "x = layers.Dense(np.prod(encoder_out_shape))(z)\n",
        "x = layers.Reshape(encoder_out_shape)(x)\n",
        "\n",
        "# Stack Deconvolutional Decoding Layers\n",
        "for filters, kernel_size, strides in \\\n",
        "    list(zip(filter_sizes, kernel_sizes, stride_sizes))[::-1]:\n",
        "  x = layers.Conv2DTranspose(filters=filters,\n",
        "                             kernel_size=kernel_size,\n",
        "                             strides=strides,\n",
        "                             activation=decoding_activation,\n",
        "                             padding='same')(x)\n",
        "\n",
        "# Finally make it into 28x28x1 and then sigmoid activation\n",
        "x = layers.Conv2DTranspose(filters=1,\n",
        "                           kernel_size=3,\n",
        "                           padding='same')(x)\n",
        "outputs = layers.Activation('sigmoid', name='decoder_output')(x)\n",
        "\n",
        "# Make the Decoder Model\n",
        "decoder = Model(z, outputs, name='decoder')\n",
        "decoder.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 784)               2352      \n",
            "_________________________________________________________________\n",
            "reshape_5 (Reshape)          (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_20 (Conv2DT (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_21 (Conv2DT (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_22 (Conv2DT (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_23 (Conv2DT (None, 28, 28, 1)         577       \n",
            "_________________________________________________________________\n",
            "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 28,385\n",
            "Trainable params: 28,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAeHrIaIfwFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "b92041b4-6b51-4c92-82e5-db4df3c751bd"
      },
      "source": [
        "# Build the Autoencoder Model by combining Encoder and Decoder Model\n",
        "\n",
        "# Define the Losses\n",
        "def autoencoder_loss(x_actual_batch, x_decoded_batch):          \n",
        "  reconstruction_loss = tf.reduce_mean(\n",
        "      keras.losses.binary_crossentropy(x_actual_batch, \n",
        "                                       x_decoded_batch)\n",
        "  )\n",
        "  reconstruction_loss *= np.prod(input_shape)\n",
        "  kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "  kl_loss = tf.reduce_mean(kl_loss)\n",
        "  kl_loss *= -0.5\n",
        "  total_loss = reconstruction_loss + kl_loss\n",
        "  return total_loss\n",
        "\n",
        "x = encoder(inputs)\n",
        "reconstruction = decoder(x[2])\n",
        "\n",
        "autoencoder = Model(inputs, reconstruction, name='autoencoder')\n",
        "autoencoder.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "encoder (Functional)         [(None, 2), (None, 2), (N 26868     \n",
            "_________________________________________________________________\n",
            "decoder (Functional)         (None, 28, 28, 1)         28385     \n",
            "=================================================================\n",
            "Total params: 55,253\n",
            "Trainable params: 55,253\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}